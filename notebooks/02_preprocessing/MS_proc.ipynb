{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b675dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in d:\\urfu\\envs\\ml-python311\\lib\\site-packages (from fastparquet) (2.3.3)\n",
      "Requirement already satisfied: numpy in d:\\urfu\\envs\\ml-python311\\lib\\site-packages (from fastparquet) (2.1.3)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.11.0-cp311-cp311-win_amd64.whl.metadata (681 bytes)\n",
      "Requirement already satisfied: fsspec in d:\\urfu\\envs\\ml-python311\\lib\\site-packages (from fastparquet) (2025.10.0)\n",
      "Requirement already satisfied: packaging in d:\\urfu\\envs\\ml-python311\\lib\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\urfu\\envs\\ml-python311\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\urfu\\envs\\ml-python311\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\urfu\\envs\\ml-python311\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\urfu\\envs\\ml-python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "Downloading fastparquet-2024.11.0-cp311-cp311-win_amd64.whl (671 kB)\n",
      "   ---------------------------------------- 0.0/671.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/671.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/671.0 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 262.1/671.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 671.0/671.0 kB 1.9 MB/s  0:00:00\n",
      "Downloading cramjam-2.11.0-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.6 MB/s  0:00:00\n",
      "Installing collected packages: cramjam, fastparquet\n",
      "\n",
      "   -------------------- ------------------- 1/2 [fastparquet]\n",
      "   ---------------------------------------- 2/2 [fastparquet]\n",
      "\n",
      "Successfully installed cramjam-2.11.0 fastparquet-2024.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e08ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Downloading pyarrow-22.0.0-cp311-cp311-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/28.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/28.1 MB 2.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 2.1/28.1 MB 3.7 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 3.7/28.1 MB 5.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.8/28.1 MB 6.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 7.3/28.1 MB 6.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 9.7/28.1 MB 7.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 12.3/28.1 MB 7.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 14.9/28.1 MB 8.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 17.3/28.1 MB 8.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 19.7/28.1 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 22.3/28.1 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 24.4/28.1 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.5/28.1 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 9.1 MB/s  0:00:03\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-22.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822dd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from fastparquet import ParquetFile\n",
    "import pyarrow\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3074fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "from src.ram import low_ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a8871a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    features = [col for col in df.columns if col not in ['id', 'FloodProbability']]\n",
    "    df['sum_risk'] = df[features].sum(axis=1)\n",
    "    df['mean_risk'] = df[features].mean(axis=1)\n",
    "    df['std_risk'] = df[features].std(axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "659698c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = Path(\"../../data/raw\")\n",
    "train_df = pd.read_csv(raw_data_dir / \"train.csv\")\n",
    "test_df = pd.read_csv(raw_data_dir / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51eaa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_features(train_df)\n",
    "test_df = add_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e5eb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1117957 entries, 0 to 1117956\n",
      "Data columns (total 25 columns):\n",
      " #   Column                           Non-Null Count    Dtype  \n",
      "---  ------                           --------------    -----  \n",
      " 0   id                               1117957 non-null  int16  \n",
      " 1   MonsoonIntensity                 1117957 non-null  int16  \n",
      " 2   TopographyDrainage               1117957 non-null  int16  \n",
      " 3   RiverManagement                  1117957 non-null  int16  \n",
      " 4   Deforestation                    1117957 non-null  int16  \n",
      " 5   Urbanization                     1117957 non-null  int16  \n",
      " 6   ClimateChange                    1117957 non-null  int16  \n",
      " 7   DamsQuality                      1117957 non-null  int16  \n",
      " 8   Siltation                        1117957 non-null  int16  \n",
      " 9   AgriculturalPractices            1117957 non-null  int16  \n",
      " 10  Encroachments                    1117957 non-null  int16  \n",
      " 11  IneffectiveDisasterPreparedness  1117957 non-null  int16  \n",
      " 12  DrainageSystems                  1117957 non-null  int16  \n",
      " 13  CoastalVulnerability             1117957 non-null  int16  \n",
      " 14  Landslides                       1117957 non-null  int16  \n",
      " 15  Watersheds                       1117957 non-null  int16  \n",
      " 16  DeterioratingInfrastructure      1117957 non-null  int16  \n",
      " 17  PopulationScore                  1117957 non-null  int16  \n",
      " 18  WetlandLoss                      1117957 non-null  int16  \n",
      " 19  InadequatePlanning               1117957 non-null  int16  \n",
      " 20  PoliticalFactors                 1117957 non-null  int16  \n",
      " 21  FloodProbability                 1117957 non-null  float32\n",
      " 22  sum_risk                         1117957 non-null  int16  \n",
      " 23  mean_risk                        1117957 non-null  float32\n",
      " 24  std_risk                         1117957 non-null  float32\n",
      "dtypes: float32(3), int16(22)\n",
      "memory usage: 59.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_df = low_ram(train_df, target_format='parquet')\n",
    "test_df = low_ram(test_df, target_format='parquet')\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf1d38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['id', 'FloodProbability'], axis=1)\n",
    "y = train_df['FloodProbability']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    random_state=69,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0b3327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Экстремальных случаев для LogReg в X_train: 177555 из 894365\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop('id', axis=1)\n",
    "test_ids = test_df['id']\n",
    "y_class_train = ((y_train > 0.54) & (X_train['sum_risk'] > 104)).astype(int)\n",
    "print(f\"Экстремальных случаев для LogReg в X_train: {y_class_train.sum()} из {len(y_class_train)}\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "log_reg = LogisticRegression(random_state=42, solver='saga', max_iter=1000, n_jobs=-1)\n",
    "log_reg.fit(X_train_scaled, y_class_train)\n",
    "train_meta = log_reg.predict_proba(X_train_scaled)[:, 1]\n",
    "val_meta = log_reg.predict_proba(X_val_scaled)[:, 1]\n",
    "test_meta = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "X_train['extreme_risk_feature'] = train_meta\n",
    "X_val['extreme_risk_feature'] = val_meta\n",
    "X_test['extreme_risk_feature'] = test_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3589634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ОК\n"
     ]
    }
   ],
   "source": [
    "output_dir = Path(\"../../data/processed\") \n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "X_train.to_parquet(output_dir / \"X_train.parquet\", index=False)\n",
    "X_val.to_parquet(output_dir / \"X_val.parquet\", index=False)\n",
    "y_train.to_frame().to_parquet(output_dir / \"y_train.parquet\", index=False)\n",
    "y_val.to_frame().to_parquet(output_dir / \"y_val.parquet\", index=False)\n",
    "X_test.to_parquet(output_dir / \"X_test.parquet\", index=False)\n",
    "pd.DataFrame({'id': test_ids}).to_parquet(output_dir / \"test_ids.parquet\", index=False)\n",
    "\n",
    "print(\"ОК\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
